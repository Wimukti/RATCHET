{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IU-XRAY Dataset\n",
    "def parse_function(filename, text):\n",
    "    # Read entire contents of image\n",
    "    image_string = tf.io.read_file(filename)\n",
    "\n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.io.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "    # This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # Resize image with padding to 244x244\n",
    "    image = tf.image.resize_with_pad(image, 224, 224, method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "    return image, text\n",
    "\n",
    "\n",
    "def augmentation_fn(image, text):\n",
    "    # Random left-right flip the image\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    # Random brightness, saturation and contrast shifting\n",
    "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
    "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "\n",
    "    # Make sure the image is still in [0, 1]\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    return image, text\n",
    "\n",
    "\n",
    "def make_grayscale_fn(image, text):\n",
    "    # Convert image to grayscale\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "\n",
    "    return image, text\n",
    "\n",
    "\n",
    "def get_iu_xray_dataset(csv_root,\n",
    "                      vocab_root,\n",
    "                      mimic_root,\n",
    "                      max_length=128,\n",
    "                      batch_size=16,\n",
    "                      n_threads=16,\n",
    "                      buffer_size=10000,\n",
    "                      mode='train',\n",
    "                      unsure=1):\n",
    "\n",
    "    assert mode in ['train', 'validate', 'test']\n",
    "    assert unsure in [0, 1]\n",
    "\n",
    "    # vocab = f.read()vocab, merges = BPE.read_file('../preprocessing/iu-xray/mimic-vocab.json', '../preprocessing/iu-xray/mimic-merges.txt')\n",
    "\n",
    "\n",
    "    # tokenizer = ByteLevelBPETokenizer(\n",
    "    #     os.path.join(vocab_root, 'mimic-vocab.json'),\n",
    "    #     os.path.join(vocab_root, 'mimic-merges.txt'),\n",
    "    # )\n",
    "\n",
    "    tokenizer = ByteLevelBPETokenizer(\n",
    "        'preprocessing/iu-xray/iu-xray-vocab.json',\n",
    "        'preprocessing/iu-xray/iu-xray-merges.txt'\n",
    "    )\n",
    "\n",
    "    # Read MIMIC_AP_PA_{mode}.csv file and set unsure values (-1) to 0 or 1\n",
    "    csv_file        = os.path.join(csv_root, f'iu_xray_{mode}.csv')\n",
    "    replacements    = {float('nan'): '0', -1.0: unsure}\n",
    "    reports         = pd.read_csv(csv_file).replace(replacements).values\n",
    "\n",
    "    image_paths     = [os.path.join(mimic_root, path) for path in reports[:, 1]]\n",
    "    texts           = reports[:, -1]\n",
    "    # labels          = np.uint8(reports[:, 2:])\n",
    "\n",
    "    # Tokenize reports\n",
    "    texts_tokenized = tokenizer.encode_batch(list(texts))\n",
    "    texts_tokenized = [[tokenizer.token_to_id('<s>')] +\n",
    "                             seq.ids +\n",
    "                             [tokenizer.token_to_id('</s>')]\n",
    "                             for seq in texts_tokenized]\n",
    "    texts_tokenized = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        texts_tokenized, maxlen=max_length, dtype='int32', padding='post', truncating='post')\n",
    "\n",
    "    # Create Tensorflow dataset (image, text) pair\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, texts_tokenized))\n",
    "    if mode == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=n_threads)\n",
    "    if mode == 'train':\n",
    "        dataset = dataset.map(augmentation_fn, num_parallel_calls=n_threads)\n",
    "    dataset = dataset.map(make_grayscale_fn, num_parallel_calls=n_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(n_threads)\n",
    "\n",
    "    return dataset, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "661c61de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-15 17:40:45.517573: [*] Using GPU(s): 0,1\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "# Initial Arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--csv_root', default='preprocessing/mimic')\n",
    "parser.add_argument('--vocab_root', default='preprocessing/mimic')\n",
    "parser.add_argument('--mimic_root', default='/data/datasets/chest_xray/MIMIC-CXR/mimic-cxr-jpg-2.0.0.physionet.org')\n",
    "parser.add_argument('--model_name', default='train05')\n",
    "parser.add_argument('--model_params', default='model/hparams.json')\n",
    "parser.add_argument('--classifier_weights', default='classifier/checkpoint/epoch_9.hdf5')\n",
    "parser.add_argument('--n_epochs', default=20)\n",
    "parser.add_argument('--init_lr', default=None)\n",
    "parser.add_argument('--batch_size', default=16)\n",
    "parser.add_argument('--resume', default=True)\n",
    "parser.add_argument('--seed', default=42)\n",
    "parser.add_argument('--max_ckpt', default=5)\n",
    "parser.add_argument('--debug_level', default='3')\n",
    "parser.add_argument('--gpu', help='comma separated list of GPU(s) to use.', default='0,1')\n",
    "parser.add_argument('--n_threads_intra_op', type=int, default=None)\n",
    "parser.add_argument('--n_threads_inter_op', type=int, default=None)\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = args.debug_level\n",
    "args.nGPU = 0 if len(args.gpu) == 0 else len(args.gpu.split(','))\n",
    "print(f'{datetime.datetime.now()}: [*] Using GPU(s): {args.gpu}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Sequence\n",
    "def main(args, hparams):\n",
    "\n",
    "    # Create strategy for distributed training\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'{datetime.datetime.now()}: [*] Number of devices: {strategy.num_replicas_in_sync}')\n",
    "\n",
    "    # Load dataset\n",
    "    BATCH_SIZE_PER_REPLICA = args.batch_size\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "    train_dataset, tokenizer = get_iu_xray_dataset(args.csv_root, args.vocab_root, args.mimic_root,\n",
    "                                                 batch_size=GLOBAL_BATCH_SIZE)\n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "\n",
    "    # Define computational graph in a Strategy wrapper\n",
    "    with strategy.scope():\n",
    "        # Define learning rate scheduler\n",
    "        print(f'{datetime.datetime.now()}: [*] Using Custom Learning Rate Scheduler')\n",
    "        learning_rate = args.init_lr if args.init_lr is not None else \\\n",
    "            CustomSchedule(hparams['d_model'], warmup_steps=len(train_dataset) // 2)\n",
    "\n",
    "        # Create Adam Optimiser\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "        # Create TF Sparse Categorical Crossentropy Loss Object\n",
    "        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "        # Loss Function\n",
    "        def loss_function(real, pred):\n",
    "            mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "            loss_ = loss_object(real, pred)\n",
    "\n",
    "            mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "            loss_ *= mask\n",
    "\n",
    "            return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
    "\n",
    "        # Define Loss and Accuracy metrics\n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "            name='train_accuracy')\n",
    "\n",
    "        # Define Model\n",
    "        target_vocab_size = tokenizer.get_vocab_size()\n",
    "        transformer = Transformer(hparams['n_layer'], hparams['d_model'],\n",
    "                                  hparams['n_head'], hparams['dff'],\n",
    "                                  target_vocab_size=target_vocab_size,\n",
    "                                  rate=hparams['dropout_rate'],\n",
    "                                  input_shape=(hparams['img_x'], hparams['img_y'], hparams['img_ch']),\n",
    "                                  # classifier_weights=args.classifier_weights\n",
    "                                  )\n",
    "\n",
    "        # Model Checkpointing\n",
    "        ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                                   optimizer=optimizer)\n",
    "        checkpoint_path = os.path.join('checkpoints', args.model_name)\n",
    "        ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=args.max_ckpt)\n",
    "        print(f'{datetime.datetime.now()}: [*] Saving {args.max_ckpt} checkpoints')\n",
    "\n",
    "        # If resume and checkpoint exists, restore the latest checkpoint.\n",
    "        init_epoch = 0\n",
    "        if args.resume:\n",
    "            if ckpt_manager.latest_checkpoint:\n",
    "                ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "                init_epoch = ckpt.save_counter.numpy()\n",
    "                print(f'{datetime.datetime.now()}: [*] Restoring Checkpoint: {ckpt_manager.latest_checkpoint}')\n",
    "            else:\n",
    "                print(f'{datetime.datetime.now()}: [*] Checkpoint not found. Skipping.')\n",
    "\n",
    "\n",
    "    def train_step(inp, tar):\n",
    "        tar_inp = tar[:, :-1]\n",
    "        tar_real = tar[:, 1:]\n",
    "\n",
    "        combined_mask = create_target_masks(tar_inp)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions, _ = transformer(inp,\n",
    "                                         tar_inp,\n",
    "                                         True,\n",
    "                                         combined_mask,\n",
    "                                         None)\n",
    "            loss = loss_function(tar_real, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "        train_accuracy(tar_real, predictions)\n",
    "\n",
    "    @tf.function()\n",
    "    def distributed_train_step(inp, tar):\n",
    "        strategy.run(train_step, args=(inp, tar))\n",
    "\n",
    "    print(f'{datetime.datetime.now()}:', '='*20, 'BEGIN TRAINING', '='*20)\n",
    "    for epoch in range(init_epoch, init_epoch + args.n_epochs):\n",
    "\n",
    "        print(f'{datetime.datetime.now()}: [*] Training: Epoch {epoch} of {init_epoch + args.n_epochs}...')\n",
    "        start = time.time()\n",
    "\n",
    "        # Reset Loss and Accuracy Metrics\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "        # Main Train Step\n",
    "        t = tqdm.tqdm(enumerate(train_dist_dataset), total=len(train_dataset))\n",
    "        t_start = datetime.datetime.now()\n",
    "        for (batch, (inp, tar)) in t:\n",
    "            distributed_train_step(inp, tar)\n",
    "            t.set_description(f'{t_start}: Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "        # Save Checkpoint\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "\n",
    "        # Print Epoch Summary\n",
    "        print(f'{datetime.datetime.now()}: '\n",
    "              f'Saving checkpoint for epoch {epoch} at {ckpt_save_path}')\n",
    "        print(f'{datetime.datetime.now()}: '\n",
    "              f'Epoch {epoch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "        print(f'{datetime.datetime.now()}: '\n",
    "              f'Time taken for epoch: {time.time() - start} secs\\n')\n",
    "\n",
    "    print(f'{datetime.datetime.now()}:', '='*20, 'TRAINING COMPLETE', '='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74be4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "    from model.transformer import Transformer, default_hparams\n",
    "    # from datasets.iu_xray import get_iu_xray_dataset\n",
    "    from model.utils import create_target_masks\n",
    "    from model.lr_scheduler import CustomSchedule\n",
    "\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    # Set Tensorflow 2.0 logging level\n",
    "    error_level = {'0': 'DEBUG', '1': 'INFO', '2': 'WARN', '3': 'ERROR'}\n",
    "    tf.get_logger().setLevel(error_level[args.debug_level])\n",
    "    print(f'{datetime.datetime.now()}: [*] Setting Tensorflow Global Logging Level: {error_level[args.debug_level]}')\n",
    "\n",
    "    # Set available CPU Threads\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(args.n_threads_intra_op)\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(args.n_threads_inter_op)\n",
    "    print(f'{datetime.datetime.now()}: [*] Intra op parallelism threads: {args.n_threads_intra_op}')\n",
    "    print(f'{datetime.datetime.now()}: [*] Inter op parallelism threads: {args.n_threads_intra_op}')\n",
    "\n",
    "    # Load mode default hyperparameters and update from file if exist\n",
    "    hparams = default_hparams()\n",
    "    if args.model_params:\n",
    "        with open(args.model_params) as json_file:\n",
    "            hparams_from_file = json.load(json_file)\n",
    "            hparams.update((k, hparams_from_file[k])\n",
    "                           for k in set(hparams_from_file).intersection(hparams))\n",
    "    print(f'{datetime.datetime.now()}: [*] Model Parameters: {hparams}')\n",
    "\n",
    "    # Set tensorflow random seed\n",
    "    tf.random.set_seed(args.seed)\n",
    "\n",
    "    # Run main training sequence\n",
    "    main(args=args, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "IU_XRAY_REPORTS = '../../IU_XRAY/indiana_reports.csv'\n",
    "\n",
    "reports = pd.read_csv(IU_XRAY_REPORTS)\n",
    "reports = reports.dropna(subset=['Reports'])  # delete empty reports\n",
    "reports = list(reports['Reports'].values)\n",
    "\n",
    "with open('/tmp/mimic.txt', 'w') as f:\n",
    "    for item in reports:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "tokenizer.train(files='/tmp/mimic.txt', vocab_size=20000, min_frequency=2, special_tokens=[\n",
    "    '<pad>',\n",
    "    '<s>',\n",
    "    '</s>',\n",
    "    '<unk>',\n",
    "    '<mask>',\n",
    "])\n",
    "\n",
    "tokenizer.save('.', 'mimic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "42acdb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>DicomPath</th>\n",
       "      <th>projection</th>\n",
       "      <th>split</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None.</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>rib pain after a XXXX, XXXX XXXX steps this XX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4_IM-2050-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n",
       "      <td>XXXX-year-old XXXX with XXXX.</td>\n",
       "      <td>None available</td>\n",
       "      <td>There are diffuse bilateral interstitial and a...</td>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5_IM-2117-1003002.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>Osteophyte/thoracic vertebrae/multiple/small;T...</td>\n",
       "      <td>Osteophyte;Thickening;Lung</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Chest and nasal congestion.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The cardiomediastinal silhouette and pulmonary...</td>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>2793</td>\n",
       "      <td>2793_IM-1226-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>Lung/hyperdistention/mild</td>\n",
       "      <td>Lung</td>\n",
       "      <td>Radiographs of the chest, 2 views, dated XXXX,...</td>\n",
       "      <td>XXXX-year-old female. Dyspnea.</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiomediastinal silhouette is normal in ...</td>\n",
       "      <td>Mild lung hyperexpansion, otherwise clear.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>2794</td>\n",
       "      <td>2794_IM-1226-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>Lung/hyperdistention;Pulmonary Disease, Chroni...</td>\n",
       "      <td>Lung;Pulmonary Disease, Chronic Obstructive</td>\n",
       "      <td>CHEST 2V FRONTAL/LATERAL XXXX, XXXX XXXX PM</td>\n",
       "      <td>in a long XXXX XXXX</td>\n",
       "      <td>XXXX, XXXX.</td>\n",
       "      <td>Lungs are hyperexpanded. No infiltrates or mas...</td>\n",
       "      <td>XXXX change COPD. No acute findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>2795</td>\n",
       "      <td>2795_IM-1227-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>Markings/lung/bilateral/diffuse/reticular/round</td>\n",
       "      <td>Markings</td>\n",
       "      <td>PA and lateral chest x-XXXX</td>\n",
       "      <td>XXXX-year-old female with edema and dyspnea.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cardiomediastinal silhouettes are within norma...</td>\n",
       "      <td>Diffuse reticulonodular pattern bilaterally. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>2796</td>\n",
       "      <td>2796_IM-1228-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Hypercalcemia</td>\n",
       "      <td>XXXX, XXXX</td>\n",
       "      <td>Cardiac and mediastinal contours are within no...</td>\n",
       "      <td>No acute process.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>2797</td>\n",
       "      <td>2797_IM-1229-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>The patient is a XXXX-year-old XXXX with chest...</td>\n",
       "      <td>None available.</td>\n",
       "      <td>The trachea is midline. The cardiomediastinal ...</td>\n",
       "      <td>No acute cardiopulmonary abnormalities. .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2695 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                  DicomPath projection  split  \\\n",
       "0        1     1_IM-0001-4001.dcm.png    Frontal  train   \n",
       "1        2     2_IM-0652-1001.dcm.png    Frontal  train   \n",
       "2        3     3_IM-1384-1001.dcm.png    Frontal  train   \n",
       "3        4     4_IM-2050-1001.dcm.png    Frontal  train   \n",
       "4        5  5_IM-2117-1003002.dcm.png    Frontal  train   \n",
       "...    ...                        ...        ...    ...   \n",
       "2690  2793  2793_IM-1226-1001.dcm.png    Frontal  train   \n",
       "2691  2794  2794_IM-1226-1001.dcm.png    Frontal  train   \n",
       "2692  2795  2795_IM-1227-1001.dcm.png    Frontal  train   \n",
       "2693  2796  2796_IM-1228-1001.dcm.png    Frontal  train   \n",
       "2694  2797  2797_IM-1229-1001.dcm.png    Frontal  train   \n",
       "\n",
       "                                                   MeSH  \\\n",
       "0                                                normal   \n",
       "1     Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "2                                                normal   \n",
       "3     Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4     Osteophyte/thoracic vertebrae/multiple/small;T...   \n",
       "...                                                 ...   \n",
       "2690                          Lung/hyperdistention/mild   \n",
       "2691  Lung/hyperdistention;Pulmonary Disease, Chroni...   \n",
       "2692    Markings/lung/bilateral/diffuse/reticular/round   \n",
       "2693                                             normal   \n",
       "2694                                             normal   \n",
       "\n",
       "                                               Problems  \\\n",
       "0                                                normal   \n",
       "1                         Cardiomegaly;Pulmonary Artery   \n",
       "2                                                normal   \n",
       "3     Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4                            Osteophyte;Thickening;Lung   \n",
       "...                                                 ...   \n",
       "2690                                               Lung   \n",
       "2691        Lung;Pulmonary Disease, Chronic Obstructive   \n",
       "2692                                           Markings   \n",
       "2693                                             normal   \n",
       "2694                                             normal   \n",
       "\n",
       "                                                  image  \\\n",
       "0                             Xray Chest PA and Lateral   \n",
       "1                   Chest, 2 views, frontal and lateral   \n",
       "2                             Xray Chest PA and Lateral   \n",
       "3     PA and lateral views of the chest XXXX, XXXX a...   \n",
       "4                             Xray Chest PA and Lateral   \n",
       "...                                                 ...   \n",
       "2690  Radiographs of the chest, 2 views, dated XXXX,...   \n",
       "2691       CHEST 2V FRONTAL/LATERAL XXXX, XXXX XXXX PM    \n",
       "2692                       PA and lateral chest x-XXXX    \n",
       "2693                          Xray Chest PA and Lateral   \n",
       "2694                          Xray Chest PA and Lateral   \n",
       "\n",
       "                                             indication       comparison  \\\n",
       "0                                      Positive TB test            None.   \n",
       "1                              Preop bariatric surgery.            None.   \n",
       "2     rib pain after a XXXX, XXXX XXXX steps this XX...              NaN   \n",
       "3                         XXXX-year-old XXXX with XXXX.   None available   \n",
       "4                           Chest and nasal congestion.              NaN   \n",
       "...                                                 ...              ...   \n",
       "2690                     XXXX-year-old female. Dyspnea.            None.   \n",
       "2691                                in a long XXXX XXXX      XXXX, XXXX.   \n",
       "2692       XXXX-year-old female with edema and dyspnea.              NaN   \n",
       "2693                                      Hypercalcemia       XXXX, XXXX   \n",
       "2694  The patient is a XXXX-year-old XXXX with chest...  None available.   \n",
       "\n",
       "                                               findings  \\\n",
       "0     The cardiac silhouette and mediastinum size ar...   \n",
       "1     Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "2                                                   NaN   \n",
       "3     There are diffuse bilateral interstitial and a...   \n",
       "4     The cardiomediastinal silhouette and pulmonary...   \n",
       "...                                                 ...   \n",
       "2690  The cardiomediastinal silhouette is normal in ...   \n",
       "2691  Lungs are hyperexpanded. No infiltrates or mas...   \n",
       "2692  Cardiomediastinal silhouettes are within norma...   \n",
       "2693  Cardiac and mediastinal contours are within no...   \n",
       "2694  The trachea is midline. The cardiomediastinal ...   \n",
       "\n",
       "                                             impression  \n",
       "0                                  Normal chest x-XXXX.  \n",
       "1                          No acute pulmonary findings.  \n",
       "2     No displaced rib fractures, pneumothorax, or p...  \n",
       "3     1. Bullous emphysema and interstitial fibrosis...  \n",
       "4                 No acute cardiopulmonary abnormality.  \n",
       "...                                                 ...  \n",
       "2690         Mild lung hyperexpansion, otherwise clear.  \n",
       "2691               XXXX change COPD. No acute findings.  \n",
       "2692  Diffuse reticulonodular pattern bilaterally. T...  \n",
       "2693                                  No acute process.  \n",
       "2694          No acute cardiopulmonary abnormalities. .  \n",
       "\n",
       "[2695 rows x 11 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset and Create CSV for train , test\n",
    "\n",
    "IU_XRAY_PROJECTIONs   = 'IU_XRAY/indiana_projections.csv'\n",
    "IU_XRAY_REPORTS = 'IU_XRAY/indiana_reports.csv'\n",
    "\n",
    "reports_df = pd.read_csv(IU_XRAY_REPORTS)\n",
    "reports_df = reports_df.drop_duplicates(subset = [\"uid\"])\n",
    "reports_df\n",
    "\n",
    "projections_df = pd.read_csv(IU_XRAY_PROJECTIONs)\n",
    "projections_df = projections_df.drop_duplicates(subset = [\"uid\"])\n",
    "projections_df\n",
    "\n",
    "iu_xray_df = pd.merge(projections_df, reports_df, how='inner', on='uid')\n",
    "iu_xray_df.rename(columns = {'filename':'DicomPath'}, inplace = True)\n",
    "iu_xray_df\n",
    "\n",
    "train_size = int(iu_xray_df.shape[0] * 0.7)\n",
    "\n",
    "iu_xray_train_csv = iu_xray_df.iloc[:train_size,:]\n",
    "iu_xray_test_csv = iu_xray_df.iloc[train_size:,:]\n",
    "\n",
    "\n",
    "iu_xray_train_csv.insert(loc=3, column='split', value='train')\n",
    "iu_xray_test_csv.insert(loc=3, column='split', value='test')\n",
    "iu_xray_train_csv\n",
    "# iu_xray_train_csv.to_csv(f'iu_xray_train.csv', index=False)\n",
    "# iu_xray_test_csv.to_csv(f'iu_xray_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RATCHET",
   "language": "python",
   "name": "ratchet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
